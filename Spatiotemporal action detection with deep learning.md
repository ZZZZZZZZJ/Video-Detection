# Spatiotemporal action detection with deep learning

## Performance comparison
| **Detector**  | **UCF-24(@IoU=0.2))**  | **J-HMDB-21(@IoU=0.5)** | **AVA 2.1** | **Published In** | 
| ------------- | ------------- | ------------- | ------------- | ------------- | 
| **Finding**  | 36.2  | 53.3  | -  | **CVPR' 15**  |
| **Tracking**  | 46.77 | 60.7  | -  | **CVPR' 15**  |
|**Multi-region**  | 42.27  | 73.09  | -  | **ECCV' 16**  |
|**STAT**| 66.75 | 72.63 | - | **BMVC' 16** |
|**AMTNet**| 60.06 | 55.31 | - |**CVPR' 17**|
|**ACT**|  77.2 | 73.7 | - | **ICCV' 17** |
|**ROAD**| 71.7 | 71.1 | - | **ICCV' 17** |
|**T-CNN**| 47.1 | 76.9 | - | **ICCV' 17**|
|**AVA**| 59.9(0.5) | 78.6 | 15.8 | **CVPR' 18**|
|**ACRN**| - | 80.1 | 17.4 | **ECCV' 18**|
|**RTPN**| 77.9 | 81.3 | 20.1 | **ECCV' 18**|
|**Better baseline**| - | - | 21.9| **arxiv' 18**|
|**Capsule**| 97.1 | 64.6 | - | **NeurIP' 18** |
|**Two-in-one**| 78.48 | 74.74 | - |**CVPR' 19** |
|**YOWO**| 75.8 | 85.7 | - | **arxiv' 19**|
|**PCSC**| 84.3 | 74.8 | - | **CVPR' 19**|
|**TACNet**| 77.5 | 73.4| - | **CVPR' 19**|
|**Hierarchy**| 82.3| 86.49 | - | **ICCV' 19**|
|**STEP**| 77.6 | - | 18.6 | **CVPR' 19**|
|**Structured**| - | - | 22.2 | **CVPR' 19**|
|**Transformer**| - | - | 25.0 | **CVPR' 19**|
|**ACAM**| - | - | 22.67 | **arxiv' 19**|
|**DTN**| - | - | 27.7 | **arxiv' 19**|
|**STAGE**| - | - | 26.3 | **arxiv' 19**|
|**LFB**| - | - | 25.5 | **CVPR' 19**|
|**SlowFast**| - | - | 28.2 | **ICCV' 19**|
|**Three branches**| - | - | 32.49 | **arxiv' 19**|


## 2020
### w/o AVA
- **AMP**: Actions as Moving Points **[arxiv' 20]** [[pdf]](https://arxiv.org/pdf/2001.04608.pdf)

## 2019
### w/ AVA
- **[STEP]**: Spatio-Temporal Progressive Learning for Video Action Detection **[CVPR' 19]** [[pdf]](https://arxiv.org/abs/1904.09288) [[code]](https://github.com/NVlabs/STEP)
- **[LFB]**: Long-Term Feature Banks for Detailed Video Understanding **[CVPR' 19]**[[pdf]](https://arxiv.org/abs/1812.05038)[[code]](https://github.com/facebookresearch/video-long-term-feature-banks)
- **[SlowFast]**: SlowFast Networks for Video Recognition **[ICCV' 19]** [[pdf]](https://arxiv.org/abs/1812.03982)[[code]](https://github.com/facebookresearch/SlowFast)
- **[STAGE]**: STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection **[arxiv' 19]** [[pdf]](https://arxiv.org/abs/1912.04316) [[code]](https://github.com/aimagelab/STAGE_action_detection)
- **[Structured]**: A Structured Model For Action Detection **[CVPR' 19]** [[pdf]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_A_Structured_Model_for_Action_Detection_CVPR_2019_paper.pdf)
- **[Transformer]**: Video Action Transformer Network **[CVPR' 19]** [[pdf]](https://arxiv.org/abs/1812.02707)
- **[DTN]**: Deformable Tube Network for Action Detection in Videos **[arxiv' 19]**[[pdf]](https://arxiv.org/pdf/1907.01847.pdf)
- **[ACAM]**: Actor Conditioned Attention Maps for Video Action Detection **[arxiv' 19]** [[pdf]](https://arxiv.org/abs/1812.11631) [[code]](https://github.com/oulutan/ACAM_Demo)
- **[AFMSAD]**: Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures **[arxiv' 19]** [[pdf]](https://arxiv.org/abs/1907.12919)
- **[SAD]**: A Study on Action Detection in the Wild **[arxiv' 19]** [[pdf]](https://arxiv.org/pdf/1904.12993.pdf)
- **[Three branches]**: Three branches: detecting actions with richer features **[arxiv' 19]** [[pdf]](https://static.googleusercontent.com/media/research.google.com/en//ava/2019/sjtu_mvig.pdf)
### w/o AVA
- **[Two-in-one]**: Dance with Flow: Two-in-One Stream Action Detection **[CVPR' 19]** [[pdf]](https://arxiv.org/abs/1904.00696) [[code ]](https://github.com/jiaozizhao/Two-in-One-ActionDetection)
- **[YOWO]**: You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization **[arxiv' 19]** [[pdf]](https://arxiv.org/abs/1911.06644) [[code]](https://github.com/wei-tim/YOWO)
- **[PCSC]**: Improving Action Localization by Progressive Cross-stream Cooperation **[CVPR' 19]** [[pdf]](https://arxiv.org/abs/1905.11575)
- **[TACNet]**: TACNet Transition-Aware Context Network for Spatio-Temporal Action Detection **[CVPR' 19]** [[pdf]](http://www.skicyyu.org/Paper/CVPR2019_TACNET.pdf)
- **[Hierarchy]**: Hierarchical Self-Attention Network for Action Localization in Videos **[ICCV' 19]** [[pdf]](http://openaccess.thecvf.com/content_ICCV_2019/html/Pramono_Hierarchical_Self-Attention_Network_for_Action_Localization_in_Videos_ICCV_2019_paper.html)

## 2018
### w/ AVA
- **[AVA]**: AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions **[CVPR' 18]** [[pdf]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Gu_AVA_A_Video_CVPR_2018_paper.pdf)
- **[ACRN]**: Actor-Centric Relation Network **[ECCV' 18]** [[pdf]](https://arxiv.org/abs/1807.10982/)
- **[RTPN]**: Recurrent Tubelet Proposal and Recognition Networks for Action Detection **[ECCV' 18]** [[pdf]](http://openaccess.thecvf.com/content_ECCV_2018/html/Dong_Li_Recurrent_Tubelet_Proposal_ECCV_2018_paper.html)
- **[Better baseline]**: A Better Baseline for AVA **[arxiv' 18]** [[pdf]](https://arxiv.org/pdf/1807.10066.pdf)[[code]](https://github.com/subhashree-r/Action_detection_AVA)
### w/o AVA
- **[Capsule]**: VideoCapsuleNet: A Simplified Network for Action Detection **[NeurIPS' 18]** [[pdf]](http://papers.nips.cc/paper/7988-videocapsulenet-a-simplified-network-for-action-detection) [[code]](https://github.com/KevinDuarte/VideoCapsuleNet)

## 2017
### w/ AVA
- **[ACT]**: Action Tubelet Detector for Spatio-Temporal Action Localization **[ICCV' 17]** [[pdf]](https://arxiv.org/abs/1705.01861) [[code]](https://github.com/imatge-upc/Action-Tubelet-Detection-in-AVA)
### w/o AVA
- **[ROAD]**: Online Real time Multiple Spatiotemporal Action Localisation and Prediction **[ICCV' 17]** [[pdf]](https://arxiv.org/pdf/1611.08563.pdf) [[code]](https://github.com/Feynman27/realtime-action-detection)
- **[Predictive-Corrective]**: Predictive-Corrective Networks for Action Detection **[CVPR' 17]** [[pdf]](http://www.achaldave.com//projects/predictive-corrective/) [[code]](https://github.com/achalddave/predictive-corrective)
- **[T-CNN]**: Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos **[ICCV' 17]** [[project]](https://www.crcv.ucf.edu/projects/TCNN/#Code)
- **[AMTnet]**: AMTnet: Action-Micro-Tube regression by end-to-end trainable deep architecture **[ICCV' 17]** [[pdf]](https://arxiv.org/pdf/1704.04952.pdf)
- Two Stream Attention Convolutional Neural Networks [[code]](https://github.com/pedro-abreu/deep-action-detection)

## 2016
- **[Multi-region]**: Multi-region two-stream R-CNN for action detection **[ECCV' 16]** [[pdf]](https://hal.inria.fr/hal-01349107v1/document) [[code]](https://github.com/pengxj/action-faster-rcnn)
- **[STAT]** : Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos **[BMVC' 16]** [[pdf]](https://arxiv.org/pdf/1608.01529v1.pdf) [[code]](https://bitbucket.org/sahasuman/bmvc2016_code/src/master/)

## 2015 
- **[Finding]**: Finding Action Tubes **[CVPR' 15]** [[project]](https://gkioxari.github.io/ActionTubes/) [[code]](https://github.com/gkioxari/ActionTubes)
- **[Track]**: Learning to track for spatio-temporal action localization **[CVPR' 15]** [[pdf]](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Weinzaepfel_Learning_to_Track_ICCV_2015_paper.pdf)
